{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "SCgp4CjgZmSl"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn #import neural network class\n",
        "from torch.utils.data import DataLoader #helps in creating batchs\n",
        "from torchvision import datasets #download data\n",
        "from torchvision.transforms import ToTensor\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## download data\n",
        "training_data = datasets.FashionMNIST(root=\"data\",train=True,download=True,transform=ToTensor())\n",
        "test_data = datasets.FashionMNIST(root=\"data\",train=False,download=True,transform=ToTensor())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HFRN_NU5cR9s",
        "outputId": "b8fc2964-f599-4d9a-cf54-75b7daabff2f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26421880/26421880 [00:01<00:00, 15903806.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/train-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29515/29515 [00:00<00:00, 259788.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4422102/4422102 [00:00<00:00, 5051521.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5148/5148 [00:00<00:00, 5940103.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "\n",
        "train_dataloader = DataLoader(training_data,batch_size=batch_size) #inputdata and Outputdata\n",
        "test_dataloader = DataLoader(test_data,batch_size=batch_size)"
      ],
      "metadata": {
        "id": "gH-N1JyGcxw7"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for X,y in train_dataloader:\n",
        "  print (X.shape)\n",
        "  print (y.shape)\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VY5GfST6dHzG",
        "outputId": "be32a09f-928f-42f3-ab93-03fab7e46f2f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 1, 28, 28])\n",
            "torch.Size([64])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_dataloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o_lbeXNwdkr7",
        "outputId": "50434eab-f159-42d6-91e0-894f2111fe50"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "938"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(test_dataloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U14S1577ePRV",
        "outputId": "5d5a390d-b9ea-464d-b0d9-705423bc6e91"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "157"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## device setup\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ],
      "metadata": {
        "id": "x28JrN3weWzY"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "djLEqZVneusD",
        "outputId": "0d41cf9f-2fde-4738-d557-30bc5633e75e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNetwork(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(NeuralNetwork,self).__init__() ##it copies the initializations from the nn.Module class\n",
        "    self.flatten = nn.Flatten() #28x28x1 is converted to 764x1\n",
        "    self.linear1 = nn.Linear(28*28,512)\n",
        "    self.linear2 = nn.Linear(512,512)\n",
        "    self.output = nn.Linear(512,10) #10 class classification problem\n",
        "\n",
        "  def forward(self,x):\n",
        "    x = self.flatten(x)\n",
        "    x = self.linear1(x)\n",
        "    x = F.relu(x)\n",
        "    x = self.linear2(x)\n",
        "    x = F.relu(x)\n",
        "    out = self.output(x) #We didn't use softmax here\n",
        "    return out"
      ],
      "metadata": {
        "id": "dYAyURpRezdY"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = NeuralNetwork().to(device)\n",
        "print (model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RpbMYNNmg45R",
        "outputId": "de4fd61e-858e-4213-bac8-77c8c9baf164"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NeuralNetwork(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear1): Linear(in_features=784, out_features=512, bias=True)\n",
            "  (linear2): Linear(in_features=512, out_features=512, bias=True)\n",
            "  (output): Linear(in_features=512, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(),lr=0.0001)"
      ],
      "metadata": {
        "id": "5NFKEPZjhKNe"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## define the training loop\n",
        "\n",
        "def train(dataloader,model,loss_fn,optimizer):\n",
        "  model.train()\n",
        "  for batch,(X,y) in enumerate(dataloader):\n",
        "    X = X.to(device)\n",
        "    y = y.to(device)\n",
        "\n",
        "    pred = model(X) #stores the variables required for gradient descent\n",
        "    loss = loss_fn(pred,y)\n",
        "\n",
        "    ##backpropogation\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    if batch % 100 == 0:\n",
        "      print (f'Loss : {loss.item()}')"
      ],
      "metadata": {
        "id": "aN9Z-8ZEiV3B"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(dataloader,model,loss_fn):\n",
        "  model.eval() #it is in test mode\n",
        "  test_loss, correct = 0,0\n",
        "  size = len(dataloader.dataset)\n",
        "  with torch.no_grad(): #What ever is inside this steps no gradient should be applied\n",
        "    for batch,(X,y) in enumerate(dataloader):\n",
        "      X,y = X.to(device), y.to(device)\n",
        "      pred = model(X) #10x1 vector\n",
        "      # print (pred.shape)\n",
        "      # print (pred.argmax(1))\n",
        "      # print (y)\n",
        "      # print ((pred.argmax(1) == y).type(torch.float).sum().item())\n",
        "      # break\n",
        "      test_loss += loss_fn(pred,y).item()\n",
        "      '''\n",
        "      pred.argmax(1) -- position of the maximum probability\n",
        "      torch.float\n",
        "      torch.int\n",
        "      torch.float32\n",
        "      '''\n",
        "      correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "  print (f'Total correct {correct} out of {size}')\n",
        "  Accuracy = correct/size\n",
        "  print (f'Accuracy : {Accuracy*100}')"
      ],
      "metadata": {
        "id": "UWrnCZjSpML6"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 5\n",
        "\n",
        "for t in range(epochs):\n",
        "  print ('Epoch---------------------------')\n",
        "  train(train_dataloader,model,loss_fn,optimizer)\n",
        "  test(test_dataloader, model, loss_fn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FsHZ-vdyjohJ",
        "outputId": "dff60710-0f01-44ae-d07e-76ec301dfe18"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch---------------------------\n",
            "Loss : 2.086418867111206\n",
            "Loss : 2.0952680110931396\n",
            "Loss : 2.054330587387085\n",
            "Loss : 2.1035802364349365\n",
            "Loss : 2.0787112712860107\n",
            "Loss : 2.02934193611145\n",
            "Loss : 2.0934078693389893\n",
            "Loss : 2.0412981510162354\n",
            "Loss : 2.071528673171997\n",
            "Loss : 2.038721799850464\n",
            "Total correct 4758.0 out of 10000\n",
            "Accuracy : 47.58\n",
            "Epoch---------------------------\n",
            "Loss : 2.0638632774353027\n",
            "Loss : 2.0723419189453125\n",
            "Loss : 2.0277509689331055\n",
            "Loss : 2.080895185470581\n",
            "Loss : 2.052708864212036\n",
            "Loss : 2.0022778511047363\n",
            "Loss : 2.0692598819732666\n",
            "Loss : 2.0137622356414795\n",
            "Loss : 2.0465035438537598\n",
            "Loss : 2.0115609169006348\n",
            "Total correct 4895.0 out of 10000\n",
            "Accuracy : 48.949999999999996\n",
            "Epoch---------------------------\n",
            "Loss : 2.0398032665252686\n",
            "Loss : 2.04766583442688\n",
            "Loss : 1.9992715120315552\n",
            "Loss : 2.0564358234405518\n",
            "Loss : 2.0246593952178955\n",
            "Loss : 1.9735620021820068\n",
            "Loss : 2.0431318283081055\n",
            "Loss : 1.9843323230743408\n",
            "Loss : 2.0197834968566895\n",
            "Loss : 1.9825905561447144\n",
            "Total correct 4997.0 out of 10000\n",
            "Accuracy : 49.97\n",
            "Epoch---------------------------\n",
            "Loss : 2.0142016410827637\n",
            "Loss : 2.0212290287017822\n",
            "Loss : 1.968928337097168\n",
            "Loss : 2.030135154724121\n",
            "Loss : 1.994565486907959\n",
            "Loss : 1.9431662559509277\n",
            "Loss : 2.015083074569702\n",
            "Loss : 1.9530647993087769\n",
            "Loss : 1.9913535118103027\n",
            "Loss : 1.9517093896865845\n",
            "Total correct 5119.0 out of 10000\n",
            "Accuracy : 51.190000000000005\n",
            "Epoch---------------------------\n",
            "Loss : 1.9870586395263672\n",
            "Loss : 1.9930808544158936\n",
            "Loss : 1.93667471408844\n",
            "Loss : 2.0019943714141846\n",
            "Loss : 1.9624184370040894\n",
            "Loss : 1.9111770391464233\n",
            "Loss : 1.985106348991394\n",
            "Loss : 1.9200600385665894\n",
            "Loss : 1.9613324403762817\n",
            "Loss : 1.9189611673355103\n",
            "Total correct 5206.0 out of 10000\n",
            "Accuracy : 52.059999999999995\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mb7fBv3rvwXH",
        "outputId": "ab5ddd3f-146c-45c0-be24-e6cb735cddde"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## save the model\n",
        "torch.save(model.state_dict(),\"/content/Myfirstmodel.pth\")"
      ],
      "metadata": {
        "id": "AoQ4az6cj3Px"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Load t\n",
        "model = NeuralNetwork().to(device)\n",
        "#torch.load_state_dict(torch.load('/content/Myfirstmodel.pth'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "id": "MWJisJ9AvNjM",
        "outputId": "ad15bdce-230a-4d92-c2a7-5e5088632543"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-59-a7ed5a1e2318>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m## Load t\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNeuralNetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/Myfirstmodel.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: module 'torch' has no attribute 'load_state_dict'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xxOZYvdiv5wA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}